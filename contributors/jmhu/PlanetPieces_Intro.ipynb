{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #PlanetPieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our journey trying to put together a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team members:  \n",
    "*Nga (Nancy) Nguyen  - Louisiana State University  \n",
    "Claire Miles - Ceres Imaging  \n",
    "Joshua Driscol - University of Washington  \n",
    "Matt Olson - Utah State University   \n",
    "Mike Leech - Environmental Science Associates  \n",
    "Shashank Bhushan - University of Washington  \n",
    "Michelle Hu - University of Washington*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose: \n",
    "\n",
    "#### To explore convolutional neural networks and train a model to identify land feature classes (vegetation, bare ground, snow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PlanetScope Analytic Ortho Tile images](https://www.planet.com/products/satellite-imagery/planetscope-analytic-ortho-tile/)  \n",
    "Collected in 2017 and 2019 between June and September\n",
    "<!-- >2017-07-25  \n",
    "2017-08-22  \n",
    "2017-09-28  \n",
    "2019-06-02  \n",
    "2019-07-25  \n",
    "2019-08-04   \n",
    "2019-08-27   -->\n",
    "  \n",
    "Delivered pre-corrected for terrain effects (using Shuttle Radar Topography Mission, Intermap, and other local elevation datasets), sensor geometry, and projected  \n",
    "  \n",
    "**Spatial resolution**: 3m   \n",
    "**Radiometric resolution**: 16 bit (top of atmosphere radiance radiometric range of 0-65536) 12 bit camera range (0 - 4096)  \n",
    "**Spectral resolution**: Four bands - blue, green, red and near infrared  \n",
    "**Spatial extent (per image)**: 25km x 25km  (8000 pixel x 8000 pixel arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <img src=\"spec_res1.png\">\n",
    "<img src=\"spec_res2.png\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Area: Mt. Rainier\n",
    "<img src=\"mtrainier_psexp.png\">\n",
    "<img src=\"mtrainier_nir.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages used:\n",
    "> numpy  \n",
    "matplotlib  \n",
    "rasterio  \n",
    "tensorflow - keras (neural network library) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  General Approach\n",
    "\n",
    "### Ideal preliminary steps  \n",
    " - Establish git workflow\n",
    " - Download data\n",
    " - Distribute data  \n",
    " - Learn what a neural network is\n",
    "  \n",
    "### Ideal processing steps  \n",
    " 1. Convert data from top-of-atmosphere radiance to top-of-atmosphere reflectance (Michelle)  \n",
    " 2. Create training dataset by labelling samples  (Nga, Matt, and Shashank)\n",
    " 3. Build, modify, and train model on training dataset (Claire and Joshua)\n",
    " 4. Classify images (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Artificial Intelligence (AI)**: \"computer-simulated intelligence\" in the imitation of human intelligence\n",
    " - **Machine learning (ML)**: information extraction by using algorithms to make decisions based on initial training (e.g. defined criteria)\n",
    "  \n",
    "     - **Deep learning**: information extraction through usage of layered algorithms (an artificial neural network - ANN) to make more complex decisions beyond bounds of initial training.  Requires lots more data than traditional ML.  \n",
    "       \n",
    "       Learning from errors occurs through minimizing loss functions discussed in the [Modeling and Optimization tutorial](https://github.com/UW-AMO/Workshop_Material).  Proper training of a deep learning model requires  weighting and curbing biases.\n",
    "     \n",
    "***But the mantra remains the same - Garbage in, Garbage out.***\n",
    "\n",
    "[1](https://skymind.ai/wiki/ai-vs-machine-learning-vs-deep-learning), [2](https://www.zendesk.com/blog/machine-learning-and-deep-learning/), [3](https://hackernoon.com/deep-learning-vs-machine-learning-a-simple-explanation-47405b3eef08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When should you choose Deep Learning?\n",
    "When you have lots and **lots of data**  \n",
    "When you have problems **too complex for machine learning**  \n",
    "When you have lots of **computational resources**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So you've decided to choose Deep Learning - but what does a neural network actually look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review from Shay's [tutorial](https://github.com/shaystrong/sagely)  \n",
    "1. The 'neurons' are just a mathematical function with weights.\n",
    "2. The number of neurons and how they are connected to each other defines an 'architecture'.\n",
    "3. We have a loss function that is iteratively checked to assess whether the neurons (and the weights) are trending to 'good': do the predictions align with the truth (this is validation data)?\n",
    "4. Weights are defined randomly (typically) to start. \n",
    "5. Iteration is where the model actually learns, and improves the weights based on that loss function.\n",
    "\n",
    "ðŸ¤” To scale across lots of data, you need to be **efficient**\n",
    "\n",
    "\"Regular Neural Nets do not scale well to full images.\"     All direct quotes, images and summaries are from http://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"neural_net2.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Input layer (single vector) -> HL1 -> HL2 -> ... -> HLN -> Output layer  \n",
    "HL = hidden layers made up of neurons that only talk to previous layer of neurons -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a regular, fully-connected neural net, images result in large weights.  \n",
    "\n",
    ">Image dimensions (4 channels - RGBN) = (4, 8000, 8000)  \n",
    "Weights = 4 * 8000 * 8000 = 256,000,000 weights\n",
    "  \n",
    "#### This is **inefficient** and predisposed to overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs) assume inputs are images  \n",
    "\n",
    "...and the architecture is structured accordingly, which allows for greater efficiency.  \n",
    "  \n",
    "Neurons are now arranged in multiple dimensions.  You go from layers to volumes.\n",
    "\n",
    "<img src=\"cnn.jpeg\">  \n",
    "\n",
    "  [1](http://cs231n.github.io/convolutional-networks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting dimensions of output volume would be 1 x 1 x depth - in this case, 1 x 1 x 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
